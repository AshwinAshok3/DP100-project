{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Deploy to an batch endpoint\n",
        "\n",
        "Imagine a health clinic takes patient measurements all day, saving the details for each patient in a separate file. Then overnight, the **OJ Sales Dominicks Store 4128 forecasting**  model can be used to process all of the future forecasting as a batch, generating predictions that will be waiting the following morning so that the clinic can follow up with Dominicks stores data that are predicted to be at @ certain sales. With Azure Machine Learning, you can accomplish this by creating a batch endpoint; and that's what you'll implement in this exercise.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the  **azure-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting azure-ai-ml\n  Downloading azure_ai_ml-1.27.1-py3-none-any.whl (13.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: azure-storage-blob>=12.10.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (12.25.1)\nRequirement already satisfied: typing-extensions<5.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.13.2)\nRequirement already satisfied: pyjwt<3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (2.4.0)\nRequirement already satisfied: colorama<1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.4.6)\nRequirement already satisfied: azure-mgmt-core>=1.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.5.0)\nCollecting strictyaml<2.0.0\n  Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pydash<9.0.0,>=6.0.0\n  Downloading pydash-8.0.5-py3-none-any.whl (102 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.17.0)\nRequirement already satisfied: isodate<1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.7.2)\nRequirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (6.0.2)\nCollecting azure-storage-file-share\n  Downloading azure_storage_file_share-12.21.0-py3-none-any.whl (290 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.6/290.6 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting azure-storage-file-datalake>=12.2.0\n  Downloading azure_storage_file_datalake-12.20.0-py3-none-any.whl (263 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.23.0)\nRequirement already satisfied: tqdm<5.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (4.67.1)\nCollecting azure-monitor-opentelemetry\n  Downloading azure_monitor_opentelemetry-1.6.10-py3-none-any.whl (25 kB)\nRequirement already satisfied: azure-core>=1.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.33.0)\nRequirement already satisfied: azure-common>=1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (1.1.28)\nCollecting marshmallow<4.0.0,>=3.5\n  Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: msrest<1.0.0,>=0.6.18 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-ml) (0.7.1)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.32.3)\nRequirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-storage-blob>=12.10.0->azure-ai-ml) (38.0.4)\nRequirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.19.1)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (2024.10.1)\nRequirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (25.3.0)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml) (25.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest<1.0.0,>=0.6.18->azure-ai-ml) (2025.1.31)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest<1.0.0,>=0.6.18->azure-ai-ml) (2.0.0)\nRequirement already satisfied: python-dateutil>=2.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from strictyaml<2.0.0->azure-ai-ml) (2.9.0.post0)\nCollecting opentelemetry-instrumentation-requests<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_requests-0.52b1-py3-none-any.whl (12 kB)\nCollecting opentelemetry-instrumentation-urllib<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_urllib-0.52b1-py3-none-any.whl (12 kB)\nCollecting opentelemetry-instrumentation-flask<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_flask-0.52b1-py3-none-any.whl (14 kB)\nCollecting azure-monitor-opentelemetry-exporter~=1.0.0b31\n  Downloading azure_monitor_opentelemetry_exporter-1.0.0b39-py2.py3-none-any.whl (155 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.9/155.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opentelemetry-resource-detector-azure~=0.1.4\n  Downloading opentelemetry_resource_detector_azure-0.1.5-py3-none-any.whl (14 kB)\nCollecting opentelemetry-instrumentation-fastapi<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_fastapi-0.52b1-py3-none-any.whl (12 kB)\nCollecting azure-core-tracing-opentelemetry~=1.0.0b11\n  Downloading azure_core_tracing_opentelemetry-1.0.0b12-py3-none-any.whl (11 kB)\nCollecting opentelemetry-instrumentation-django<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_django-0.52b1-py3-none-any.whl (19 kB)\nCollecting opentelemetry-instrumentation-psycopg2<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_psycopg2-0.52b1-py3-none-any.whl (10 kB)\nCollecting opentelemetry-instrumentation-urllib3<0.53b0,>=0.49b0\n  Downloading opentelemetry_instrumentation_urllib3-0.52b1-py3-none-any.whl (13 kB)\nCollecting opentelemetry-sdk<1.32,>=1.28.0\n  Downloading opentelemetry_sdk-1.31.1-py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: opentelemetry-api>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (1.32.0)\nCollecting psutil<8,>=5.9\n  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: azure-identity~=1.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml) (1.21.0)\nCollecting fixedint==0.1.6\n  Downloading fixedint-0.1.6-py3-none-any.whl (12 kB)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (1.17.1)\nCollecting opentelemetry-instrumentation==0.52b1\n  Downloading opentelemetry_instrumentation-0.52b1-py3-none-any.whl (31 kB)\nCollecting opentelemetry-semantic-conventions==0.52b1\n  Downloading opentelemetry_semantic_conventions-0.52b1-py3-none-any.whl (183 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting opentelemetry-instrumentation-wsgi==0.52b1\n  Downloading opentelemetry_instrumentation_wsgi-0.52b1-py3-none-any.whl (14 kB)\nCollecting opentelemetry-util-http==0.52b1\n  Downloading opentelemetry_util_http-0.52b1-py3-none-any.whl (7.3 kB)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-django<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (1.14.1)\nRequirement already satisfied: deprecated>=1.2.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-semantic-conventions==0.52b1->opentelemetry-instrumentation-django<0.53b0,>=0.49b0->azure-monitor-opentelemetry->azure-ai-ml) (1.2.18)\nCollecting opentelemetry-api>=1.12.0\n  Downloading opentelemetry_api-1.31.1-py3-none-any.whl (65 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-api>=1.12.0->azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (8.2.0)\nCollecting opentelemetry-instrumentation-asgi==0.52b1\n  Downloading opentelemetry_instrumentation_asgi-0.52b1-py3-none-any.whl (16 kB)\nCollecting asgiref~=3.0\n  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\nCollecting opentelemetry-instrumentation-dbapi==0.52b1\n  Downloading opentelemetry_instrumentation_dbapi-0.52b1-py3-none-any.whl (12 kB)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (1.26.20)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.10)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest<1.0.0,>=0.6.18->azure-ai-ml) (3.2.2)\nRequirement already satisfied: msal-extensions>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-identity~=1.17->azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml) (1.2.0)\nRequirement already satisfied: msal>=1.30.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-identity~=1.17->azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml) (1.31.2b1)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (2.22)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.12.0->azure-core-tracing-opentelemetry~=1.0.0b11->azure-monitor-opentelemetry->azure-ai-ml) (3.19.2)\nRequirement already satisfied: portalocker<3,>=1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msal-extensions>=1.2.0->azure-identity~=1.17->azure-monitor-opentelemetry-exporter~=1.0.0b31->azure-monitor-opentelemetry->azure-ai-ml) (2.10.1)\nInstalling collected packages: fixedint, pydash, psutil, opentelemetry-util-http, marshmallow, asgiref, strictyaml, opentelemetry-api, opentelemetry-semantic-conventions, azure-storage-file-share, azure-core-tracing-opentelemetry, opentelemetry-sdk, opentelemetry-instrumentation, azure-storage-file-datalake, opentelemetry-resource-detector-azure, opentelemetry-instrumentation-wsgi, opentelemetry-instrumentation-urllib3, opentelemetry-instrumentation-urllib, opentelemetry-instrumentation-requests, opentelemetry-instrumentation-dbapi, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-psycopg2, opentelemetry-instrumentation-flask, opentelemetry-instrumentation-fastapi, opentelemetry-instrumentation-django, azure-monitor-opentelemetry-exporter, azure-monitor-opentelemetry, azure-ai-ml\n  Attempting uninstall: psutil\n    Found existing installation: psutil 5.2.2\n    Uninstalling psutil-5.2.2:\n      Successfully uninstalled psutil-5.2.2\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.32.0\n    Uninstalling opentelemetry-api-1.32.0:\n      Successfully uninstalled opentelemetry-api-1.32.0\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.53b0\n    Uninstalling opentelemetry-semantic-conventions-0.53b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.53b0\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.32.0\n    Uninstalling opentelemetry-sdk-1.32.0:\n      Successfully uninstalled opentelemetry-sdk-1.32.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmlflow-skinny 2.21.3 requires packaging<25, but you have packaging 25.0 which is incompatible.\njupyterlab-nvdashboard 0.13.0 requires jupyterlab>=4, but you have jupyterlab 3.6.8 which is incompatible.\njupyter-resource-usage 0.7.2 requires psutil~=5.6, but you have psutil 7.0.0 which is incompatible.\ndask-sql 2024.5.0 requires dask[dataframe]>=2024.4.1, but you have dask 2023.2.0 which is incompatible.\ndask-sql 2024.5.0 requires distributed>=2024.4.1, but you have distributed 2023.2.0 which is incompatible.\nazureml-training-tabular 1.60.0 requires psutil<5.9.4,>=5.2.2, but you have psutil 7.0.0 which is incompatible.\nazureml-training-tabular 1.60.0 requires scipy<1.11.0,>=1.0.0, but you have scipy 1.11.0 which is incompatible.\nazureml-mlflow 1.60.0 requires azure-storage-blob<=12.19.0,>=12.5.0, but you have azure-storage-blob 12.25.1 which is incompatible.\nazureml-automl-runtime 1.60.0 requires psutil<5.9.4,>=5.2.2, but you have psutil 7.0.0 which is incompatible.\nazureml-automl-dnn-nlp 1.60.0 requires torch==2.2.2, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed asgiref-3.8.1 azure-ai-ml-1.27.1 azure-core-tracing-opentelemetry-1.0.0b12 azure-monitor-opentelemetry-1.6.10 azure-monitor-opentelemetry-exporter-1.0.0b39 azure-storage-file-datalake-12.20.0 azure-storage-file-share-12.21.0 fixedint-0.1.6 marshmallow-3.26.1 opentelemetry-api-1.31.1 opentelemetry-instrumentation-0.52b1 opentelemetry-instrumentation-asgi-0.52b1 opentelemetry-instrumentation-dbapi-0.52b1 opentelemetry-instrumentation-django-0.52b1 opentelemetry-instrumentation-fastapi-0.52b1 opentelemetry-instrumentation-flask-0.52b1 opentelemetry-instrumentation-psycopg2-0.52b1 opentelemetry-instrumentation-requests-0.52b1 opentelemetry-instrumentation-urllib-0.52b1 opentelemetry-instrumentation-urllib3-0.52b1 opentelemetry-instrumentation-wsgi-0.52b1 opentelemetry-resource-detector-azure-0.1.5 opentelemetry-sdk-1.31.1 opentelemetry-semantic-conventions-0.52b1 opentelemetry-util-http-0.52b1 psutil-7.0.0 pydash-8.0.5 strictyaml-1.7.3\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1751291323177
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1751291339157
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1751291346140
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Register the model\n",
        "\n",
        "Batch deployments can only deploy models registered in the workspace. You'll register an MLflow model, which is stored in the local `model` folder. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci00b7cf28ae7f478cbf/code/Users/User1-52618447/DP100-project/Final model/notebook'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1751291533293
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "folder_path_model = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci00b7cf28ae7f478cbf/code/Users/User1-52618447/DP100-project/Final model/scripts/mlruns/923865445274044016/bfa291c9fe12495d9ef7715ac2b6a421/artifacts/sarimax_model\"\n",
        "model_name = 'sarimax_model'\n",
        "model = ml_client.models.create_or_update(\n",
        "    Model(name=model_name, path=folder_path_model, type=AssetTypes.MLFLOW_MODEL)\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[32mUploading sarimax_model (24.86 MBs): 100%|██████████| 24864300/24864300 [00:00<00:00, 85176454.83it/s]\n\u001b[39m\n\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1751291682409
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create a batch endpoint\n",
        "\n",
        "A batch endpoint is an HTTPS endpoint that applications can call to trigger a batch scoring job. A batch endpoint name needs to be unique within an Azure region. You'll use the `datetime` function to generate a unique name based on the current date and time. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "endpoint_name = \"batch-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "endpoint_name"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "'batch-06301354336591'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1751291693248
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "To create an endpoint with the `BatchEndpoint` class, you need to specify the name and optionally a description. After creating an endpoint, you'll deploy a model to the endpoint."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import BatchEndpoint\n",
        "\n",
        "# create a batch endpoint\n",
        "endpoint = BatchEndpoint(\n",
        "    name=endpoint_name,\n",
        "    description=\"A batch endpoint for forecasting dominicks sales fore store 4128\",\n",
        ")\n",
        "\n",
        "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "<azure.core.polling._poller.LROPoller at 0x708e0e7c7a00>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1751291719203
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the endpoint is created before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "## Create the deployment\n",
        "\n",
        "A deployment is a set of resources required for hosting the model that does the actual inferencing. We will create a deployment for our endpoint using the `BatchDeployment` class. \n",
        "\n",
        "Since you're deploying an MLflow model, you don't need a scoring script or define the environment. Azure Machine Learning will automatically create those assets for you. The `MLmodel` file in the `model` folder is used to understand what the expected inputs and outputs are of the model.\n",
        "\n",
        "You'll deploy a model with the following parameters:\n",
        "\n",
        "- `name`: Name of the deployment.\n",
        "- `description`: Optional description to further clarify what the deployment represents.\n",
        "- `endpoint_name`: Name of the previously created endpoint the model should be deployed to.\n",
        "- `model`: Name of the registered model.\n",
        "- `compute`: Compute to be used when invoking the deployed model to generate predictions.\n",
        "- `instance_count`: Count of compute nodes to use for generating predictions.\n",
        "- `max_concurrency_per_instance`: Maximum number of parallel scoring script runs per compute node.\n",
        "- `mini_batch_size`: Number of files passed per scoring script run.\n",
        "- `output_action`: Each new prediction will be appended as a new row to the output file.\n",
        "- `output_file_name`: File to which predictions will be appended.\n",
        "- `retry_settings`: Settings for a mini-batch fails.\n",
        "- `logging_level`: The log verbosity level. Allowed values are `warning`, `info`, and `debug`. \n",
        "\n",
        "Running the following cell will configure and create the deployment.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import BatchDeployment, BatchRetrySettings\n",
        "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
        "\n",
        "deployment = BatchDeployment(\n",
        "    name=\"ojdominicks-store4128\",\n",
        "    description=\"A time series forecasting model\",\n",
        "    endpoint_name=endpoint.name,\n",
        "    model=model,\n",
        "    compute=\"aml-cluster\",\n",
        "    instance_count=2,\n",
        "    max_concurrency_per_instance=2,\n",
        "    mini_batch_size=2,\n",
        "    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
        "    output_file_name=\"predictions.csv\",\n",
        "    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
        "    logging_level=\"info\",\n",
        ")\n",
        "ml_client.batch_deployments.begin_create_or_update(deployment)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/ai/ml/entities/_deployment/batch_deployment.py:137: UserWarning: This class is intended as a base class and it's direct usage is deprecated. Use one of the concrete implementations instead:\n* ModelBatchDeployment - For model-based batch deployments\n* PipelineComponentBatchDeployment - For pipeline component-based batch deployments\n  warnings.warn(\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "<azure.core.polling._poller.LROPoller at 0x708de9d1d630>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1751291804297
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the deployment is completed before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "You can deploy multiple models to an endpoint. You can set the default deployment to specify which model should be used by default when calling a batch endpoint."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint.defaults = {}\n",
        "\n",
        "endpoint.defaults[\"deployment_name\"] = deployment.name\n",
        "\n",
        "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "<azure.core.polling._poller.LROPoller at 0x708dea1975e0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1751291877097
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the default deployment is set before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "## Prepare the data for batch predictions\n",
        "\n",
        "In the `data` folder you'll find CSV files with unlabeled data. You'll create a data asset that points to the files in the `data` folder, which you'll use as input for the batch job."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "data_path = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci00b7cf28ae7f478cbf/code/Users/User1-52618447/DP100-project/Final model/data/X_test.csv\"\n",
        "dataset_name = \"forecasting-test-data\"\n",
        "\n",
        "forecasting_test_set = Data(\n",
        "    path=data_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"A forecasting sales data from OJ for store 4128 dominicks\",\n",
        "    name=dataset_name,\n",
        ")\n",
        "ml_client.data.create_or_update(forecasting_test_set)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "Data({'path': 'azureml://subscriptions/604342bf-c5b7-46e8-8eef-def8c102e8b6/resourcegroups/rg-dp100-l00b7cf28ae7f478cbf/workspaces/mlw-dp100-l00b7cf28ae7f478cbf/datastores/workspaceblobstore/paths/LocalUpload/7555d43b746c8321fde484982c016854/X_test.csv', 'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'forecasting-test-data', 'description': 'A forecasting sales data from OJ for store 4128 dominicks', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/604342bf-c5b7-46e8-8eef-def8c102e8b6/resourceGroups/rg-dp100-l00b7cf28ae7f478cbf/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-l00b7cf28ae7f478cbf/data/forecasting-test-data/versions/2', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci00b7cf28ae7f478cbf/code/Users/User1-52618447/DP100-project/Final model/notebook', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x708de9de5d80>, 'serialize': <msrest.serialization.Serializer object at 0x708de9de4700>, 'version': '2', 'latest_version': None, 'datastore': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1751292089282
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forecasting_test_set = ml_client.data.get(\n",
        "    name=\"forecasting-test-data\", label=\"latest\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1751292227284
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Submit the job\n",
        "\n",
        "Now that you have deployed a model to a batch endpoint, and have an unlabeled data asset, you're ready to invoke the endpoint to generate predictions on the unlabeled data.\n",
        "\n",
        "First, you'll define the input by referring to the registered data asset. Then, you'll invoke the endpoint, which will submit a pipeline job. You can use the job URL to monitor it in the Studio. The job will contain a child job that represents the running of the (generated) scoring script to get the predictions."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import Input\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "input = Input(type=AssetTypes.URI_FILE, path=forecasting_test_set.id)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1751292257130
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = ml_client.batch_endpoints.invoke(\n",
        "    endpoint_name=endpoint.name, \n",
        "    input=input)\n",
        "\n",
        "ml_client.jobs.get(job.name)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "PipelineJob({'inputs': {}, 'outputs': {}, 'jobs': {}, 'component': PipelineComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': \"Attempting to create pipeline submission settings for endpoint: 'batch-06301354336591', deployment: 'ojdominicks-store4128'.\", 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci00b7cf28ae7f478cbf/code/Users/User1-52618447/DP100-project/Final model/notebook', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x708de98461a0>, 'version': '1', 'schema': None, 'type': 'pipeline', 'display_name': 'patient_crayon_5vxdg91n', 'is_deterministic': None, 'inputs': {}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {}, 'job_types': {}, 'job_sources': {}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'batchjob-9b7f10a4-690d-43a4-8e74-22ac1c58dca2', 'description': \"Attempting to create pipeline submission settings for endpoint: 'batch-06301354336591', deployment: 'ojdominicks-store4128'.\", 'tags': {'outputType': 'output_data', 'output_data_name': None, 'inputType': 'input_data', 'azureml.batchrun': 'true', 'azureml.deploymentname': 'ojdominicks-store4128', 'azureml.jobtype': 'azureml.batchjob'}, 'properties': {'azureml.deploymentname': 'ojdominicks-store4128', 'azureml.endpointname': 'batch-06301354336591', 'azureml.pipelineid': 'e0952fae-1e04-4a19-9631-019bf99e6fdb', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{\"run_max_try\":\"3\",\"run_invocation_timeout\":\"300\",\"mini_batch_size\":\"2\",\"error_threshold\":\"-1\",\"logging_level\":\"INFO\",\"process_count_per_node\":\"2\",\"NodeCount\":\"2\",\"append_row_file_name\":\"predictions.csv\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': False, 'id': '/subscriptions/604342bf-c5b7-46e8-8eef-def8c102e8b6/resourceGroups/rg-dp100-l00b7cf28ae7f478cbf/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-l00b7cf28ae7f478cbf/jobs/batchjob-9b7f10a4-690d-43a4-8e74-22ac1c58dca2', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci00b7cf28ae7f478cbf/code/Users/User1-52618447/DP100-project/Final model/notebook', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x708de9847700>, 'serialize': <msrest.serialization.Serializer object at 0x708de98449d0>, 'display_name': 'patient_crayon_5vxdg91n', 'experiment_name': 'batch-06301354336591', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://northeurope.api.azureml.ms/mlflow/v1.0/subscriptions/604342bf-c5b7-46e8-8eef-def8c102e8b6/resourceGroups/rg-dp100-l00b7cf28ae7f478cbf/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-l00b7cf28ae7f478cbf?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/batchjob-9b7f10a4-690d-43a4-8e74-22ac1c58dca2?wsid=/subscriptions/604342bf-c5b7-46e8-8eef-def8c102e8b6/resourcegroups/rg-dp100-l00b7cf28ae7f478cbf/workspaces/mlw-dp100-l00b7cf28ae7f478cbf&tid=4cfe372a-37a4-44f8-91b2-5faf34253c62', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>batch-06301354336591</td><td>batchjob-9b7f10a4-690d-43a4-8e74-22ac1c58dca2</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/batchjob-9b7f10a4-690d-43a4-8e74-22ac1c58dca2?wsid=/subscriptions/604342bf-c5b7-46e8-8eef-def8c102e8b6/resourcegroups/rg-dp100-l00b7cf28ae7f478cbf/workspaces/mlw-dp100-l00b7cf28ae7f478cbf&amp;tid=4cfe372a-37a4-44f8-91b2-5faf34253c62\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1751292270560
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Get the results\n",
        "\n",
        "When the pipeline job that invokes the batch endpoint is completed, you can view the results. All predictions are collected in the `predictions.csv` file that is stored in the default datastore. You can download the file and visualize the data by running the following cells. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.jobs.download(name=job.name, download_path=\".\", output_name=\"score\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "JobException",
          "evalue": "This job is in state Running. Download is allowed only in states ['Completed', 'Failed', 'Canceled', 'NotResponding', 'Paused']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJobException\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/core/tracing/decorator.py:138\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m span_attributes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    137\u001b[0m                 span\u001b[38;5;241m.\u001b[39madd_attribute(key, value)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Native path\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/ai/ml/_telemetry/activity.py:288\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mstart_as_current_span(ACTIVITY_SPAN):\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[1;32m    286\u001b[0m             logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[1;32m    287\u001b[0m         ):\n\u001b[0;32m--> 288\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_logger\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger\u001b[38;5;241m.\u001b[39mpackage_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/ai/ml/operations/_job_operations.py:918\u001b[0m, in \u001b[0;36mJobOperations.download\u001b[0;34m(self, name, download_path, output_name, all)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job_status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m RunHistoryConstants\u001b[38;5;241m.\u001b[39mTERMINAL_STATUSES:\n\u001b[1;32m    915\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis job is in state \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Download is allowed only in states \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    916\u001b[0m         job_status, RunHistoryConstants\u001b[38;5;241m.\u001b[39mTERMINAL_STATUSES\n\u001b[1;32m    917\u001b[0m     )\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JobException(\n\u001b[1;32m    919\u001b[0m         message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m    920\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mJOB,\n\u001b[1;32m    921\u001b[0m         no_personal_data_message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m    922\u001b[0m         error_category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    923\u001b[0m     )\n\u001b[1;32m    925\u001b[0m is_batch_job \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    926\u001b[0m     job_details\u001b[38;5;241m.\u001b[39mtags\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazureml.batchrun\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m job_details\u001b[38;5;241m.\u001b[39mtags\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazureml.jobtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m PipelineConstants\u001b[38;5;241m.\u001b[39mPIPELINE_JOB_TYPE\n\u001b[1;32m    928\u001b[0m )\n\u001b[1;32m    929\u001b[0m outputs \u001b[38;5;241m=\u001b[39m {}\n",
            "\u001b[0;31mJobException\u001b[0m: This job is in state Running. Download is allowed only in states ['Completed', 'Failed', 'Canceled', 'NotResponding', 'Paused']"
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1751292473041
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "score = pd.read_csv(\"predictions.csv\", index_col=0, names=[\"Date\", \"prediction\", \"file\"])\n",
        "score"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667817550830
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}