{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wx6MlsjodAZr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPYzZWzCdIDS"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQUFr6nAdGY9"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from azureml.opendatasets import OjSalesSimulated\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pmdarima as pm # Used for AutoARIMA model\n",
    "\n",
    "# Set plot style for better visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "# Optional: Suppress warnings from pmdarima for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"--- Starting Orange Juice Sales Forecasting Notebook ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIVuOez_dRG6"
   },
   "source": [
    "# Import Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "collapsed": true,
    "id": "Zeqw_qz1dGlQ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a801502e-7c54-47d3-8260-39a9c9fdae1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.1 & 1.2 Fetching OjSalesSimulated dataset and loading into Pandas DataFrame...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'OjSalesSimulated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1-3475935736.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# into memory as a Pandas DataFrame for immediate use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n1.1 & 1.2 Fetching OjSalesSimulated dataset and loading into Pandas DataFrame...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moj_sales_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOjSalesSimulated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OjSalesSimulated' is not defined"
     ]
    }
   ],
   "source": [
    "# --- 1. Data Importing and Initial Inspection ---\n",
    "\n",
    "# Step 1.1 & 1.2: Fetch the OjSalesSimulated dataset and convert it to a Pandas DataFrame in a single line.\n",
    "# This command connects to Azure's open datasets, retrieves the dataset, and directly loads all its data\n",
    "# into memory as a Pandas DataFrame for immediate use.\n",
    "print(\"\\n1.1 & 1.2 Fetching OjSalesSimulated dataset and loading into Pandas DataFrame...\")\n",
    "oj_sales_df = OjSalesSimulated.get_file_dataset().to_pandas_dataframe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8SoQxN8dGn5"
   },
   "outputs": [],
   "source": [
    "# Step 1.3: Display the first few rows of the DataFrame.\n",
    "# This helps in quickly understanding the columns, their names, and the type of data they contain.\n",
    "print(\"\\n--- 1.3 Initial Data Head ---\")\n",
    "print(oj_sales_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imm_v_FedGqa"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 1.4: Display basic information about the DataFrame.\n",
    "# 'info()' provides a summary including column data types, number of non-null values, and memory usage.\n",
    "# This is useful for identifying missing values or incorrect data types.\n",
    "print(\"\\n--- 1.4 DataFrame Info ---\")\n",
    "oj_sales_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxAlFQHmdGs5"
   },
   "outputs": [],
   "source": [
    "# Step 1.5: Display descriptive statistics for numerical columns.\n",
    "# 'describe()' provides statistics like count, mean, standard deviation, min, max, and quartiles.\n",
    "# This gives a quick overview of the distribution and range of numerical data.\n",
    "print(\"\\n--- 1.5 Descriptive Statistics ---\")\n",
    "print(oj_sales_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05VP8EbTePCP"
   },
   "source": [
    "# --- Data Preparation ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvOpmb6hdGxl"
   },
   "outputs": [],
   "source": [
    "# Step 2.1: Convert the 'WeekStarting' column to datetime objects.\n",
    "# This is a critical step for any time series analysis, as it allows Pandas to recognize\n",
    "# the column as a time index and enables time-based operations.\n",
    "print(\"\\n2.1 Converting 'WeekStarting' to datetime...\")\n",
    "oj_sales_df['WeekStarting'] = pd.to_datetime(oj_sales_df['WeekStarting'])\n",
    "\n",
    "# Step 2.2: Sort the entire DataFrame.\n",
    "# Sorting by 'Store', 'Brand', and then 'WeekStarting' ensures that for each\n",
    "# unique combination of store and brand, the sales data is in chronological order.\n",
    "# This is essential for correct time series modeling.\n",
    "print(\"2.2 Sorting data by Store, Brand, and WeekStarting...\")\n",
    "oj_sales_df = oj_sales_df.sort_values(by=['Store', 'Brand', 'WeekStarting'])\n",
    "\n",
    "# Step 2.3: Identify all unique combinations of 'Store' and 'Brand'.\n",
    "# Each unique 'Store'-'Brand' pair represents an individual time series for which\n",
    "# we want to build a separate forecasting model.\n",
    "unique_series_ids = oj_sales_df[['Store', 'Brand']].drop_duplicates().reset_index(drop=True)\n",
    "print(f\"\\nTotal unique Store-Brand combinations found: {len(unique_series_ids)}\")\n",
    "\n",
    "# --- Configuration for Forecasting ---\n",
    "target_column = 'Quantity'  # The variable we want to predict.\n",
    "time_column = 'WeekStarting' # The time axis.\n",
    "forecast_horizon = 10       # Number of future weeks to forecast (e.g., 10 weeks).\n",
    "season_length = 52          # Number of periods in a seasonal cycle (52 weeks in a year for weekly data).\n",
    "\n",
    "# --- List to store aggregated results ---\n",
    "all_forecast_results = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAMBaHg-eU3x"
   },
   "source": [
    "# -- Iterate Train Predict Evaluate and PLot the computes data -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ro-VBHkWc8m0"
   },
   "outputs": [],
   "source": [
    "# --- 3. Iterate, Train, Predict, Evaluate, and Plot for Each Time Series ---\n",
    "\n",
    "print(\"\\n--- 3. Starting Model Training and Prediction for Each Series ---\")\n",
    "print(\"    (This process will be very time-consuming for all series and will generate many plots.)\")\n",
    "print(\"    Consider using 'unique_series_ids = unique_series_ids.head(5)' to test with a small subset.\")\n",
    "\n",
    "# Uncomment the line below to test with a smaller number of series (e.g., 5 for quick check)\n",
    "# unique_series_ids = unique_series_ids.head(5) # REMOVE OR COMMENT FOR FULL RUN\n",
    "\n",
    "# Step 3.1: Loop through each unique time series (Store-Brand combination).\n",
    "for index, row in unique_series_ids.iterrows():\n",
    "    current_store = row['Store']\n",
    "    current_brand = row['Brand']\n",
    "\n",
    "    # Step 3.2: Filter the DataFrame for the current store and brand.\n",
    "    # This isolates the data for a single, independent time series.\n",
    "    single_series_df = oj_sales_df[\n",
    "        (oj_sales_df['Store'] == current_store) &\n",
    "        (oj_sales_df['Brand'] == current_brand)\n",
    "    ].copy() # .copy() avoids warnings about modifying a slice\n",
    "\n",
    "    # Step 3.3: Basic check for sufficient data.\n",
    "    # We need enough data to split into training and testing sets.\n",
    "    if len(single_series_df) < 2 * forecast_horizon:\n",
    "        print(f\"  Skipping Store: {current_store}, Brand: {current_brand} - Not enough data ({len(single_series_df)} points).\")\n",
    "        continue\n",
    "\n",
    "    # Step 3.4: Data Splitting (Time-based).\n",
    "    # For time series, we split data chronologically. The last 'forecast_horizon' periods\n",
    "    # are reserved for testing (evaluation), and the rest for training.\n",
    "    split_date = single_series_df[time_column].max() - pd.Timedelta(weeks=forecast_horizon)\n",
    "    train_data = single_series_df[single_series_df[time_column] <= split_date].copy()\n",
    "    test_data = single_series_df[single_series_df[time_column] > split_date].copy()\n",
    "\n",
    "    # Get the actual target values for comparison.\n",
    "    actual_values = test_data[target_column].values\n",
    "\n",
    "    # Check if training data is empty after split (e.g., very short series).\n",
    "    if train_data.empty:\n",
    "        print(f\"  Skipping Store: {current_store}, Brand: {current_brand} - Empty training data after split.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing Store: {current_store}, Brand: {current_brand}\")\n",
    "    print(f\"  Train data points: {len(train_data)}\")\n",
    "    print(f\"  Test data points (forecast horizon): {len(test_data)}\")\n",
    "\n",
    "    # --- 4. Model Training, Prediction, and Evaluation for Each Model Type ---\n",
    "\n",
    "    # --- Model Type 1: Naive Forecast ---\n",
    "    # The Naive forecast simply predicts the last observed value from the training data\n",
    "    # for all future forecast steps.\n",
    "    last_train_value = train_data[target_column].iloc[-1]\n",
    "    naive_predictions = np.full(shape=len(test_data), fill_value=last_train_value)\n",
    "\n",
    "    # Calculate Root Mean Squared Error (RMSE) for Naive model.\n",
    "    rmse_naive = np.sqrt(mean_squared_error(actual_values, naive_predictions))\n",
    "    print(f\"  Naive Forecast RMSE: {rmse_naive:.2f}\")\n",
    "\n",
    "    # --- Model Type 2: Seasonal Naive Forecast ---\n",
    "    # The Seasonal Naive forecast predicts the value from the same period in the last\n",
    "    # completed seasonal cycle in the training data.\n",
    "    seasonal_train_values = np.array([])\n",
    "    if len(train_data) >= season_length:\n",
    "        # Extract the last full season's worth of data from the training set.\n",
    "        seasonal_train_values = train_data[target_column].iloc[-season_length:].values\n",
    "    else:\n",
    "        # Fallback: if not enough data for a full season, use a simpler approach or default.\n",
    "        # Here, we'll repeat the last known value for the season length if not enough.\n",
    "        print(f\"    Warning: Not enough data for full season ({season_length} weeks) for Seasonal Naive. Using last available value for some forecasts.\")\n",
    "        # Create a proxy for seasonal values by repeating the last observed value\n",
    "        seasonal_train_values = np.full(shape=season_length, fill_value=last_train_value)\n",
    "\n",
    "    # Generate predictions by repeating the seasonal pattern.\n",
    "    seasonal_naive_predictions = np.array([\n",
    "        seasonal_train_values[i % len(seasonal_train_values)] # Use modulo to loop through seasonal values\n",
    "        for i in range(len(test_data))\n",
    "    ])\n",
    "\n",
    "    # Calculate RMSE for Seasonal Naive model.\n",
    "    rmse_seasonal_naive = np.sqrt(mean_squared_error(actual_values, seasonal_naive_predictions))\n",
    "    print(f\"  Seasonal Naive Forecast RMSE: {rmse_seasonal_naive:.2f}\")\n",
    "\n",
    "    # --- Model Type 3: AutoARIMA Forecast ---\n",
    "    # AutoARIMA (from pmdarima) automatically searches for the best ARIMA (p,d,q)(P,D,Q)m\n",
    "    # parameters for the given time series based on information criteria (e.g., AIC).\n",
    "    y_train_arima = train_data[target_column].values\n",
    "\n",
    "    arima_predictions = np.full(shape=len(test_data), fill_value=np.nan) # Initialize with NaNs\n",
    "    rmse_arima = np.nan # Initialize RMSE as NaN\n",
    "\n",
    "    try:\n",
    "        # Fit the AutoARIMA model.\n",
    "        arima_model = pm.auto_arima(y_train_arima,\n",
    "                                    start_p=1, start_q=1, # Starting non-seasonal AR/MA orders\n",
    "                                    max_p=5, max_q=5,     # Maximum non-seasonal AR/MA orders\n",
    "                                    m=season_length,      # Seasonal period\n",
    "                                    seasonal=True,        # Enable search for seasonal components\n",
    "                                    d=None, D=None,       # Let auto_arima determine differencing orders\n",
    "                                    trace=False,          # Do not print search progress for each trial\n",
    "                                    error_action='ignore',# Ignore errors if a particular ARIMA order fails\n",
    "                                    suppress_warnings=True, # Suppress warnings from internal statsmodels\n",
    "                                    stepwise=True)        # Use stepwise (greedy) search for efficiency\n",
    "\n",
    "        # Make predictions for the forecast horizon using the trained ARIMA model.\n",
    "        arima_predictions = arima_model.predict(n_periods=len(test_data))\n",
    "\n",
    "        # Calculate RMSE for AutoARIMA model.\n",
    "        rmse_arima = np.sqrt(mean_squared_error(actual_values, arima_predictions))\n",
    "        print(f\"  AutoARIMA Forecast RMSE: {rmse_arima:.2f}\")\n",
    "\n",
    "        # Note: In a real-world scenario (especially with Azure ML Pipelines),\n",
    "        # you would save this 'arima_model' using joblib.dump for later deployment.\n",
    "        # Example: joblib.dump(arima_model, f'./models/arima_store_{current_store}_brand_{current_brand}.pkl')\n",
    "        # For this local notebook, we just train and predict.\n",
    "\n",
    "    except Exception as e:\n",
    "        # If AutoARIMA fails for a specific series (e.g., due to flat data or convergence issues),\n",
    "        # print an error and record NaN for RMSE.\n",
    "        print(f\"  AutoARIMA failed for Store: {current_store}, Brand: {current_brand}. Error: {e}\")\n",
    "\n",
    "    # --- 5. Store and Visualize Results for the Current Series ---\n",
    "\n",
    "    # Step 5.1: Create a DataFrame to hold predictions and actuals for the current series.\n",
    "    series_forecasts_df = pd.DataFrame({\n",
    "        'Store': current_store,\n",
    "        'Brand': current_brand,\n",
    "        'WeekStarting': test_data[time_column],\n",
    "        'ActualQuantity': actual_values,\n",
    "        'NaiveForecast': naive_predictions,\n",
    "        'SeasonalNaiveForecast': seasonal_naive_predictions,\n",
    "        'AutoARIMAForecast': arima_predictions\n",
    "    })\n",
    "    # Also store the RMSEs\n",
    "    series_forecasts_df['RMSE_Naive'] = rmse_naive\n",
    "    series_forecasts_df['RMSE_SeasonalNaive'] = rmse_seasonal_naive\n",
    "    series_forecasts_df['RMSE_AutoARIMA'] = rmse_arima\n",
    "\n",
    "    # Append the results of the current series to the aggregated list.\n",
    "    all_forecast_results.append(series_forecasts_df)\n",
    "\n",
    "    # Step 5.2: Plotting Actual vs. Forecasted Quantities for the current series.\n",
    "    # This loop will generate a plot for each series.\n",
    "    # It's highly recommended to only plot for a small subset of series during development\n",
    "    # to avoid overwhelming your display with thousands of plots.\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(train_data[time_column], train_data[target_column], label='Training Data', color='blue', alpha=0.7)\n",
    "    plt.plot(test_data[time_column], actual_values, label='Actual Test Data', color='green', linewidth=2)\n",
    "    plt.plot(test_data[time_column], naive_predictions, label='Naive Forecast', linestyle='--', color='red')\n",
    "    plt.plot(test_data[time_column], seasonal_naive_predictions, label='Seasonal Naive Forecast', linestyle=':', color='purple')\n",
    "    if not np.isnan(rmse_arima): # Only plot ARIMA if it successfully ran\n",
    "        plt.plot(test_data[time_column], arima_predictions, label='AutoARIMA Forecast', linestyle='-.', color='orange')\n",
    "\n",
    "    plt.title(f'Sales Forecast for Store {current_store}, Brand {current_brand}')\n",
    "    plt.xlabel('Week Starting')\n",
    "    plt.ylabel('Quantity')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout() # Adjust layout to prevent overlapping\n",
    "    plt.show() # Display the plot for the current series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoVLDoPtejwc"
   },
   "source": [
    "# summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmm_B7GMel10"
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 6. Aggregate and Summarize Overall Performance ---\n",
    "\n",
    "# Step 6.1: Concatenate all individual forecast results into a single DataFrame.\n",
    "final_forecast_output = pd.concat(all_forecast_results, ignore_index=True)\n",
    "\n",
    "print(\"\\n--- 6.1 All Forecasting Completed and Results Aggregated ---\")\n",
    "print(\"\\nFinal Forecasts (first 5 rows of aggregated output):\")\n",
    "print(final_forecast_output.head())\n",
    "\n",
    "print(\"\\nFinal Forecasts (DataFrame Info):\")\n",
    "final_forecast_output.info()\n",
    "\n",
    "# Step 6.2: Calculate average RMSE for each model type across all series.\n",
    "# We'll drop rows where AutoARIMA might have failed (NaN RMSE).\n",
    "avg_rmse_naive = final_forecast_output['RMSE_Naive'].mean()\n",
    "avg_rmse_seasonal_naive = final_forecast_output['RMSE_SeasonalNaive'].mean()\n",
    "avg_rmse_arima = final_forecast_output['RMSE_AutoARIMA'].mean() # This will be NaN if any ARIMA failed, filter first\n",
    "\n",
    "# Filter out NaN for more accurate average for AutoARIMA if some failed\n",
    "filtered_arima_rmse = final_forecast_output['RMSE_AutoARIMA'].dropna()\n",
    "avg_rmse_arima = filtered_arima_rmse.mean()\n",
    "\n",
    "print(\"\\n--- 6.3 Overall Model Performance (Average RMSE) ---\")\n",
    "print(f\"Average RMSE for Naive Forecast: {avg_rmse_naive:.2f}\")\n",
    "print(f\"Average RMSE for Seasonal Naive Forecast: {avg_rmse_seasonal_naive:.2f}\")\n",
    "print(f\"Average RMSE for AutoARIMA Forecast: {avg_rmse_arima:.2f} (based on {len(filtered_arima_rmse)} successful runs)\")\n",
    "\n",
    "\n",
    "# --- 7. Save Aggregated Results (Optional) ---\n",
    "# You can save the final combined predictions and metrics to a CSV file.\n",
    "output_csv_path = 'oj_sales_all_forecast_results.csv'\n",
    "final_forecast_output.to_csv(output_csv_path, index=False)\n",
    "print(f\"\\nAggregated forecast results saved to '{output_csv_path}'\")\n",
    "\n",
    "print(\"\\n--- Notebook Execution Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
